---
title: "ANOVA Assgnment 4"
author: "Tim Farkas"
date: "4/7/2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, results = FALSE)
setwd("~/Dropbox/3_Education/Courses/stat_545_anova/code/")
library(tidyverse)
```

## Problem 20.5  
```{r, echo = FALSE}
dd <- tibble(type = as_factor(rep(c("exec", "sci"), each = 4)), 
             size = rep(2:5, 2), 
             ideas = c(18, 22, 31, 32, 15, 23, 29, 33))

dd %>%
  ggplot() +
  geom_line(aes(x = size, y = ideas, color = type))
```

**a**  

**Does it appear that interaction effects are present?**

Well, these aren't perfectly parallel lines, as we'd prefer to see if the assumption of no interaction were true. In particular, the executives appear to produce more ideas when in group sizes of 2 and 4, whereas the difference is rather small in the other direction for group sizes 3 and 5. That said, there's not a consistent pattern evident here, and the magnitude of interaction present is pretty small, likely a non-important interaction. So all in all, I'd probably say it's at least not a flagrant violation to assume no interaction given these results. 

**Does it appear that factor A and factor B main effects are present?**
I'd say there's essentially no evidence for a difference between participant type, but there's a clear positive, and rather linear relationship between group size and the number of ideas generated. The shape is somewhat sigmoid for executives, but it's still very linear. 

**b**

```{r}

dd_aug <- dd %>% 
  ungroup() %>%
  group_by(size) %>%
  mutate(size_means = mean(ideas)) %>%
  group_by(type) %>%
  mutate(type_means = mean(ideas)) %>%
  ungroup() %>%
  mutate(grand_mean = mean(ideas), 
         sqerr = (ideas - size_means - type_means + grand_mean)^2)

ideas <- dd %>%
  pull(ideas)

type_means <- dd %>%
  group_by(type) %>%
  dplyr::summarize(across(ideas, mean)) %>%
  pull(ideas)

size_means <- dd %>%
  group_by(size) %>%
  dplyr::summarize(across(ideas, mean)) %>%
  pull(ideas)

grand_mean <- mean(dd$ideas)

mstype = length(size_means) * sum((type_means - grand_mean)^2) / 
  (length(type_means) - 1)

mssize = length(type_means) * sum((size_means - grand_mean)^2) / 
  (length(size_means) - 1)

msab <- sum(dd_aug$sqerr) / ((length(type_means) - 1) * (length(size_means) - 1))

F_type <- mstype / msab
F_size <- mssize / msab

Fcrit_type <- qf(0.99, 1, 3)
Fcrit_size <- qf(0.99, 3, 3)

1 - pf(F_type, 1, 3)
1 - pf(F_size, 3, 3)
```

For subject type (A): 

$$H_0: \mu_{exec} = \mu_{sci}$$
$$H_{\alpha}: \mu_{exec} \ne \mu_{sci}$$
Decision Rule: $F* > F(0.99, 1, 3)$ = 34.11

$$F^*_A = \frac{MSA}{MSAB} = \frac{1.125}{2.125} = .529$$
So the hypothesis is falsified, with a p-value of 0.519.

For group size (B): 

$$H_0: \mu_{2} = \mu_{3} = \mu_4 = \mu_5$$
$$H_{\alpha}: otherwise$$
Decision Rule: $F* > F(0.99, 3, 3)$ = 29.46

$$F^*_A = \frac{MSB}{MSAB} = \frac{106.125}{2.125} = 49.94$$

So we reject the null hypothesis that the number of ideas generated by groups of different sizes are equal, with a p-value of 0.0017.

An upper bound for the family level of significance is 

$$\alpha \le 1 - (1 - \alpha_A)(1 - \alpha_B) = 0.0199$$

## **c.**  

```{r}
#size_means
diffs <- diff(size_means)
sdiff <- msab
B <- qt(1 - .05/6, 8-4)
bdiff <- B * sdiff

diffs + bdiff
diffs - bdiff

```

The 95% confidence intervals with Bonferroni correction are 

$$D_1: (-2.42, 14.417)$$
$$D_2: (-0.92, 15.92)$$
$$D_3: (-5.92, 10.92)$$
Using Bonferroni correction, we find no significant differences between the group sizes, since the 95% confidence interval crosses 0 in each case. 

## **d.**

Can't be sure without testing, but it's likely that the Bonferroni correction is better here because the Tukey test would correct for $\binom{4}{2} = 6$ comparisons, whereas here we're only interested in 3. The Scheffe correction would be even more conservative than Tukey.

## 20.7

```{r}
ssto <- dd_aug %>%
  mutate(sqerr = (ideas - grand_mean)^2) %>%
  pull(sqerr) %>% sum

ssa <- mstype * (length(type_means) - 1)
ssb <- mssize * (length(size_means) - 1)
ssab <- msab * (length(type_means) - 1) * (length(size_means) - 1)
ssrem <- ssto - ssa - ssb - ssab

sqrtnum <- dd_aug %>%
  mutate(num = ideas * (size_means - grand_mean) * (type_means - grand_mean)) %>% 
  pull(num) %>% sum()

num <- sqrtnum^2

denom  <- sum((size_means - grand_mean)^2) * sum((type_means - grand_mean)^2)

ssabstar <- num/denom

ssrem <- ssto - ssabstar - ssa - ssb

fstar <- ssabstar * (8 - 4 - 2) / ssrem

```

The Tukey test of additivity test the hypothesis: 

$$H_0: all (\alpha\beta)_{ij} = 0$$
$$H_{\alpha}: otherwise $$ 

The decision rule is:

$$F* > F(0.95, 1, 2) = 18.51$$
For the conclusion: 

$$F^* = \frac{SSAB^* \times (ab - a - b)}{SSRem^*} = 0.599$$

So we fail to reject the hypothesis of additivity, and conclude the no-interaction model is appropriate. If we were to find evidence of interaction here, we could try data transformations to remove them. One option would be the Box-Cox proceduce to search for an appropriate transformation, profiling with the F-statistic from the Tukey test. 

## Code Appendix

```{r, echo = TRUE, eval = FALSE}
dd <- tibble(type = as_factor(rep(c("exec", "sci"), each = 4)), 
             size = rep(2:5, 2), 
             ideas = c(18, 22, 31, 32, 15, 23, 29, 33))

dd %>%
  ggplot() +
  geom_line(aes(x = size, y = ideas, color = type))
```

```{r, echo = TRUE, eval = FALSE}

dd_aug <- dd %>% 
  ungroup() %>%
  group_by(size) %>%
  mutate(size_means = mean(ideas)) %>%
  group_by(type) %>%
  mutate(type_means = mean(ideas)) %>%
  ungroup() %>%
  mutate(grand_mean = mean(ideas), 
         sqerr = (ideas - size_means - type_means + grand_mean)^2)

ideas <- dd %>%
  pull(ideas)

type_means <- dd %>%
  group_by(type) %>%
  dplyr::summarize(across(ideas, mean)) %>%
  pull(ideas)

size_means <- dd %>%
  group_by(size) %>%
  dplyr::summarize(across(ideas, mean)) %>%
  pull(ideas)

grand_mean <- mean(dd$ideas)

mstype = length(size_means) * sum((type_means - grand_mean)^2) / 
  (length(type_means) - 1)

mssize = length(type_means) * sum((size_means - grand_mean)^2) / 
  (length(size_means) - 1)

msab <- sum(dd_aug$sqerr) / ((length(type_means) - 1) * (length(size_means) - 1))

F_type <- mstype / msab
F_size <- mssize / msab

Fcrit_type <- qf(0.99, 1, 3)
Fcrit_size <- qf(0.99, 3, 3)

1 - pf(F_type, 1, 3)
1 - pf(F_size, 3, 3)
```

```{r, echo = TRUE, eval = FALSE}
size_means
diffs <- diff(size_means)
sdiff <- msab
B <- qt(1 - .05/6, 8-4)
bdiff <- B * sdiff

diffs + bdiff
diffs - bdiff

```

```{r, echo = TRUE, eval = FALSE}
ssto <- dd_aug %>%
  mutate(sqerr = (ideas - grand_mean)^2) %>%
  pull(sqerr) %>% sum

ssa <- mstype * (length(type_means) - 1)
ssb <- mssize * (length(size_means) - 1)
ssab <- msab * (length(type_means) - 1) * (length(size_means) - 1)
ssrem <- ssto - ssa - ssb - ssab

sqrtnum <- dd_aug %>%
  mutate(num = ideas * (size_means - grand_mean) * (type_means - grand_mean)) %>% 
  pull(num) %>% sum()

num <- sqrtnum^2

denom  <- sum((size_means - grand_mean)^2) * sum((type_means - grand_mean)^2)

ssabstar <- num/denom

ssrem <- ssto - ssabstar - ssa - ssb

fstar <- ssabstar * (8 - 4 - 2) / ssrem

```
